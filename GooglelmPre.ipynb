{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"C:/Users/HP/AppData/Local/Programs/Python/Python37-32/Lib/site-packages\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Conv2D, Flatten,MaxPooling2D,Dropout,ZeroPadding2D,BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "import tarfile\n",
    "import zipfile\n",
    "import urllib\n",
    "import urllib.request\n",
    "import hashlib\n",
    "import requests\n",
    "import sys\n",
    "import requests\n",
    "import cv2\n",
    "import glob\n",
    "import re \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions \n",
    "Helper functions , Tar extract , Resize files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Helper Function #######################\n",
    "#            ExtractTarFile      ######################\n",
    "#  Extract Tar all files (regerdless of the directory)#\n",
    "#  Structure from a Tar file                          #\n",
    "#  Paramters :                                        #\n",
    "#  FileName - The Tar file name                       #\n",
    "#  TargetDirectory - The target to place the          #\n",
    "#  extracted files                                    #\n",
    "#  DeleteAtEnd - If true delete the Tar file          #\n",
    "\n",
    "\n",
    "def ExtractTarFile(FileName,TargetDirectory,DeleteAtEnd):\n",
    "    #Try to create the directory (in case not exist)\n",
    "    if(os.path.exists(TargetDirectory)==False):\n",
    "        os.mkdir(TargetDirectory)\n",
    "    #Iterate over the Tar file and Extract all files \n",
    "    with tarfile.open(FileName, 'r:tar') as _tar:\n",
    "        for member in _tar:\n",
    "            if member.isdir():\n",
    "                continue\n",
    "            fname = member.name.rsplit('/',1)[1]\n",
    "            _tar.makefile(member, TargetDirectory + '/' + fname)\n",
    "    #Delete Tr file (if DeletAtEnd is True )\n",
    "    if (DeleteAtEnd):\n",
    "        os.remove(FileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Helper Function #######################\n",
    "#            BatchResizeImages     #####################\n",
    "#  Resize All Jpg file in the directory               #\n",
    "#  Structure from a Tar file                          #\n",
    "#  Paramters :                                        #\n",
    "#  SourceDirectory - Source Directory                 #\n",
    "#  TargetDirectory - The target to place the          #\n",
    "#  extracted files                                    #\n",
    "#  DeleteAtEnd - If true delete the Tar file          #\n",
    "#  width  - Target Image width                        #\n",
    "#  height  - Target Image height                      #\n",
    "\n",
    "\n",
    "def BatchResizeImages(SourceDirectory,TargetDirectory,DeleteAtEnd,width,height):\n",
    "\n",
    "\n",
    "    cwd = os.getcwd()\n",
    "    os.chdir(\"E:/Elements/kaggle/GoogleLandmarkRecognition2019\")\n",
    "\n",
    "    # Get images\n",
    "    imgs = glob.glob('*.jpg')\n",
    "    imgs.extend(glob.glob('*.jpeg'))\n",
    "\n",
    "    \n",
    "\n",
    "    #print('Resizing all images be %d pixels wide' % width)\n",
    "\n",
    "    folder = TargetDirectory\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    # Iterate through resizing and saving\n",
    "    for img in imgs:\n",
    "        pic = cv2.imread(img, cv2.IMREAD_UNCHANGED)\n",
    "        #height = int(width * pic.shape[0] / pic.shape[1])\n",
    "        pic = cv2.resize(pic, (width, height))\n",
    "        cv2.imwrite(folder + '/' + img, pic)\n",
    "        if (DeleteAtEnd):\n",
    "            os.remove(img)\n",
    "    \n",
    "    #Go back to the original directory \n",
    "    os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Helper Function #######################\n",
    "#            Zip Files             #####################\n",
    "#  Zip all files in a directory                       #\n",
    "#                                                     #\n",
    "#  Paramters :                                        #\n",
    "#  folder_path - Source Directory                    #\n",
    "#  output_path - The target zip file                 #\n",
    "#                                                    #\n",
    "\n",
    "\n",
    "def zip_folder(folder_path, output_path):\n",
    "    \n",
    "    parent_folder = os.path.dirname(folder_path)\n",
    "    # Retrieve the paths of the folder contents.\n",
    "    contents = os.walk(folder_path)\n",
    "   \n",
    "    zip_file = zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED)\n",
    "    for root, folders, files in contents:\n",
    "            # Include all subfolders, including empty ones.\n",
    "            for folder_name in folders:\n",
    "                absolute_path = os.path.join(root, folder_name)\n",
    "                relative_path = absolute_path.replace(parent_folder + '\\\\',\n",
    "                                                      '')\n",
    "                #print (\"Adding '%s' to archive.\" % absolute_path)\n",
    "                zip_file.write(absolute_path, relative_path)\n",
    "            for file_name in files:\n",
    "                absolute_path = os.path.join(root, file_name)\n",
    "                relative_path = absolute_path.replace(parent_folder + '\\\\',\n",
    "                                                      '')\n",
    "                #print (\"Adding '%s' to archive.\" % absolute_path)\n",
    "                zip_file.write(absolute_path, relative_path)\n",
    "    #print(\"'%s' created successfully.\" % output_path)\n",
    "    zip_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download image files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare All URL location from 000 to 500\n",
    "Base_Url= 'https://s3.amazonaws.com/google-landmark/train/images_XXX.tar'\n",
    "Base_Target = 'images_XXX.tar'\n",
    "URL_List = []\n",
    "Target_List = []\n",
    "for i in  range(500):\n",
    "    counter  = (str(format(i, '0003d')))\n",
    "    URL_List.append(re.sub('XXX', counter, Base_Url))\n",
    "    Target_List.append(re.sub('XXX', counter, Base_Target))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start_Index = 5\n",
    "#Stop_Index = 51\n",
    "\n",
    "#for i in  range(Start_Index,Stop_Index):\n",
    "#    print(URL_List[i])\n",
    "#    print(Target_List[i])\n",
    "#    print(\"downloading  file\",i)\n",
    "#    myfile = requests.get(URL_List[i],verify=False, timeout=10)\n",
    "#    open(Target_List[i], 'wb').write(myfile.content)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3.amazonaws.com/google-landmark/train/images_467.tar\n",
      "images_467.tar\n",
      "downloading  file 467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "Start_Index = 467\n",
    "Stop_Index = 500\n",
    "Base_Dir = \"E:/Elements/kaggle/GoogleLandmarkRecognition2019/X.resized\"\n",
    "\n",
    "for i in  range(Start_Index,Stop_Index):\n",
    "    #Download Tar \n",
    "    print(URL_List[i])\n",
    "    print(Target_List[i])\n",
    "    print(\"downloading  file\",i)\n",
    "    myfile = requests.get(URL_List[i],verify=False, timeout=10)\n",
    "    open(Target_List[i], 'wb').write(myfile.content)\n",
    "    #Extract Tar \n",
    "    ExtractTarFile(Target_List[i],\"E:/Elements/kaggle/GoogleLandmarkRecognition2019\",DeleteAtEnd=True)\n",
    "    Target = re.sub('X', str(i), Base_Dir)\n",
    "    #Resize \n",
    "    BatchResizeImages(\"E:/Elements/kaggle/GoogleLandmarkRecognition2019\",Target,True,128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#zip_folder(\"E:/Elements/kaggle/GoogleLandmarkRecognition2019\",\"E:/Elements/kaggle/GoogleLandmarkRecognition2019/zipfile.zip\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
